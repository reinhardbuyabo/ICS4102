{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMM53rU3/QhKl3rn+T+OEjL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reinhardbuyabo/ICS4102/blob/main/linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhZ1xH3oQq0f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "9u0ByUMCQxkg",
        "outputId": "8d3d827d-bdc8-491b-9fcd-86e769fae8d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.0.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DnLCIS54UASJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##generate data\n",
        "np.random.seed(0)  # for reproducibility\n",
        "def rand_X_y_LR(nsamples=None, nfeatures=None, plot_XY = False):\n",
        "\n",
        "        # Define the number of samples and features\n",
        "        num_samples = nsamples\n",
        "        num_features = nfeatures\n",
        "\n",
        "        # Generate a random design matrix X with values between 0 and 1\n",
        "        X = np.random.rand(num_samples, num_features)\n",
        "        print(f\"shape of random X; {X.shape}\")\n",
        "        ones_column = np.ones((len(X), 1))\n",
        "        print(f\"shape ones_column, {ones_column.shape}\")\n",
        "        X_plusOnes=np.hstack([ones_column, X])\n",
        "        print(f\"shape of X_plusOnes_column, {X_plusOnes.shape}\")\n",
        "\n",
        "        # Generate random coefficients for the features\n",
        "        true_coefficients = np.random.normal(loc=0, scale=1, size=(num_features+1))\n",
        "        print(f\"shape of true_coefficients; {true_coefficients.shape}\")\n",
        "\n",
        "        # Generate random noise for the target variable\n",
        "        noise = np.random.normal(loc=0, scale=1)\n",
        "\n",
        "        # Calculate the target variable y using a linear combination of X and coefficients\n",
        "        #y = np.dot(X_plusOnes, true_coefficients) + noise #X dot B\n",
        "        y =  X_plusOnes @ true_coefficients + noise #X@B\n",
        "        print(f\"y.shape; {y.shape}\")\n",
        "\n",
        "        if plot_XY == True:\n",
        "            #plot each X column against target\n",
        "            fig, axes = plt.subplots(nrows=round(num_features/2), ncols=2, figsize=(9, 7))\n",
        "            for i, ax in enumerate(axes.flat):\n",
        "              ax.scatter(Xdata_in[:, i], y_data_in)\n",
        "              ax.set_xlabel(f\"Xdata_in_col {i}\")\n",
        "              ax.set_ylabel('Target')\n",
        "              ax.set_title(f\"Xdata_in_col {i} vrs Target\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            #fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(9, 7))\n",
        "            plt.figure(figsize=(4,5))\n",
        "            plt.hist(y_data_in)\n",
        "            plt.title('Target distribution')\n",
        "            plt.show()\n",
        "            plt.figure(figsize=(4,5))\n",
        "            plt.hist(true_coefficients)\n",
        "            plt.title('true_coefficients')\n",
        "            plt.show()\n",
        "\n",
        "        return X, y, true_coefficients\n",
        "\n",
        "# Generating random dataset of size 1024x10 for X\n",
        "Xdata_in, y_data_in, true_beta = rand_X_y_LR(nsamples=200, nfeatures=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V45o7cKxQ0hM",
        "outputId": "949bd559-e059-42da-badb-69739289ec1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of random X; (200, 0)\n",
            "shape ones_column, (200, 1)\n",
            "shape of X_plusOnes_column, (200, 1)\n",
            "shape of true_coefficients; (1,)\n",
            "y.shape; (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression:\n",
        "  def __init__(self, lr=0.001, n_iters=1000):\n",
        "    self.lr = lr\n",
        "    self.n_iters = n_iters\n",
        "    self.weights = None\n",
        "    self.bias = None\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    n_samples, n_features = X.shape\n",
        "    self.weights = np.zeros(n_features)\n",
        "    self.bias = 0\n",
        "\n",
        "    for _ in range(n_iters):\n",
        "      y_pred  = np.dot(X, self.weights) + self.bias\n",
        "\n",
        "      dw = (1/n_samples) * np.dot(X, (y_pred-y))\n",
        "      db = (1/n_samples) * np.sum(y_pred-y)\n",
        "\n",
        "      # updating weights\n",
        "      self.weight = self.weight - self.lr * dw\n",
        "      self.bias = self.bias - self.lr * db\n",
        "\n",
        "  def predict(self, X): # self and a new dataset\n",
        "    y_pred = np.dot(X, self.weights) + self.bias\n",
        "    return y_pred"
      ],
      "metadata": {
        "id": "-YBHZs2iZ2f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tg_bavyDcujJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}